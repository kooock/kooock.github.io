---
layout: post
title: "텐서는 도대체 뭘까?"
excerpt: "텐서에 대한 얕은 고찰"
modified: 2020-05-06
tags: [딥러닝, 텐서, 개발, 파이토치, 텐서플로우]
comments: true
category: DeepLearning
---

# 텐서(tensor)에 대하여

오늘 pytorch 튜토리얼을 보다가 묻득 ...

![useful image]({{ site.url }}/assets/images/Untitled.png)

어? matrix하고 tensor하고 다른건 알겠는데 뭐가 다른거였더라? 라는 본질적인 의문이 갑자기 들었다. 그래서 폭풍검색을 하며 자료를 찾아나가기 시작했다. 

먼저 위키피디아 

![useful image]({{ site.url }}/assets/images/Untitled%201.png)

음.....그만 알아보자.

읽는 것도 힘들다 

그런 중에 아주 중요한 핵심개념을 알게 되었다. 그것은 바로 tensor의 rank

그렇다. 롤처럼 tensor도 등급제가 있었던 거임

일단은 거기까지 안 상태에서 텐서는 왜 만든 것이며, 어디다가 쓰는 것일까

![useful image]({{ site.url }}/assets/images/tensor.jpg)

아인슈타인 선생님의 장 방정식에도 쓴다고... 그러고 저기 uv(사실 유브이 아님 '뮤뉴'임 ~~적당히 넘어가지~~) 달린 저것들이 metric tensor(측량텐서)인가 뭔가라고 한다.  장 무서워 텐서에 발 못 담그겠다 ~~그만알아보자~~

그리고 

![useful image]({{ site.url }}/assets/images/_.jpg)

~~몇마리의 고양이가 죽어나가야 양자역학에서 고양이 이야기를 안할까....~~

양자역학에서 양자 얽힘은 서로 다른 두 텐서가 곱해져서 만들어진다고 한다.  그래....많이 곱하시구여.....

그래 뭐..... 알다가도 모르 아니 모르다가도 더 모르겠다. 

![useful image]({{ site.url }}/assets/images/tensor%201.jpg)

## 텐서는 행렬일까

결론부터 말하자면 행렬과 텐서는 다르다

> "rank 2의 텐서는 행렬이 될 수 있지만 모든 행렬이 텐서가 되는건 아니다"

뭔가 더 어렵다. 엑스창 누르지 말고 우리 같이 알아보자 이게 무슨 개쌉소리인지

## rank란 무엇인가

위에도 말했듯이 텐서는 롤 티어마냥 rank라는 등급이 있다

우리 잘 생각해보자 사실 수학에서 등급나누는게 어떤게 있는지

1.  백터랑 스칼라랑 뭐가 다를까?
2. 백터보다 더 높은 차원은?

자 백터와 스칼라랑 다른걸 알 수 있는 짤을 소개해주겠다 

![useful image]({{ site.url }}/assets/images/Untitled%202.png)

이래서 눈치빠른 이과는 안된다니까 

그렇다 스칼라는 크기만 있고 백터는 방향을 가지고 있다. 그렇다 **방향**이다 방향 

여기에 비밀이 숨겨져 있다. 

우린 벌써 두가지 rank의 tensor를 목격했다

(응 뭐라고?)

자 우리는 4차원 시공간에 산다고 한다. 여기서 잠시 시간을 놓아주면 우리는 3차원 공간에 있다. 

그렇다면 스칼라는 크기만 있고 방향이 없으니 1개의 성분(크기)으로 이루어져있다고 볼 수 있다. 

자 그렇다면 백터는 크기도 있고 방향이 있다! 방향이 있다는 말은 무엇일까? 사실 각 성분의 크기가 있다고 할 수 있다. 자 그렇다면 여기서 우린 백터는 3개의 성분이 있다고 할 수 있다. 여기엔 방향에 대한 정보가 숨겨져 있다 

자 바로 이 1개의 성분이 있는 스칼라가 rank 0의 tensor이며, 3개의 성분이 있는 백터가 rank 1의 tensor인 것이다. 

아직도 의문일 것이다. 왜냐 나도 그랬으니까. 자 그럼 여기서 문제를 내보겠다 

"스칼라의 크기를 바꾸려면 무엇을 곱해야 하나요?"

이 문제는 구구단 선에서 정리된다.

스칼라의 모든성분 그러니까 크기를 바꾸려면 스칼라를 곱하면 된다 

하지만 백터에 스칼라를 곱해서 크기와 방향를 모두 바꿀 수 있는가  크기까지 바꿀순 있지만 방향까지 바꿀 순 없다. 

그렇다면 백터에 백터를 곱하면 크기와 방향을 바꿀 수 있을까 일단 내적을 하면 스칼라가 되어 버린다. 그렇다고 외적을 한다고 해도 직각방향으로만 바뀔 뿐이다. 우린 뭔가 다른 대안이 필요하다 그래서 우린 Dyad를 만들어 내야 한다.  

즉 더 많은 성분을 가진 무엇인가로 참교육을 해줘야 한다. 

3 개의 성분에서 각 성분당 3개의 성분으로 확장시키기 위해 우린 새로운 product(곱하기) 만든다. 

a = a1i + a2j + a3k이고 

b = b1i + b2j + b3k일때 

(i j k는 단위백터다. 즉 성분을 나타낸다)

![useful image]({{ site.url }}/assets/images/Untitled%203.png)

우린 이런 곱의 형태를 이제 dyad product라고 하겠다. 

-ㅌ이 ab의 형태의 dyad는 rank1의 백터의 크기와 방향을 모두 바꾼다. 

심지어 이 형태는 방향을 두개 가진다. (머릿속으로 상상하지 마라 어차피 안된다)

여기서 보면 ii부터 kk까지가 성분인데 9개로 늘었다. 

이게 바로 rank 2의 tensor이다. 이런식으로 확장하면 rank 3은 방향이 3개이고 성분은 27개이다. 

그렇다 rank는 방향의 수와 같다고 볼 수 있다. 

우리 사실 tensor가 하나의 변환에 대한 operator로 작용할 수 있다는 사실을 알아냈다. 

사실 여기까지가 물리학에서 주로 바라보는 개념이고(엥?) 이제 수학적으로 보도록 하자

## 좌표계와 tensor

스칼라는 크기만 가지고 있다. 내가 던파 레벨이(-틀-) 한국에서  30이었으면 미국에서도 30이다. 이건 변하지 않는다. 즉 어디라도 이 스칼라의 크기는 변하지 않는다. 이것은 rank 0짜리 tensor이다 

백터는 크가와 방향을 가지고 있다. 예시로 음 뭐가 좋을까....음... 나의 크고 우람한 오이를 가지고 이야기해보겠다. 내가 이 오이를 살포시 들어서

![useful image]({{ site.url }}/assets/images/Untitled%204.png)

거실에서 방까지 가지고 간다(사실 우리집 원룸이다 암튼) 오이의 아무런 미동도 없이 내가 몸도 틀지 않고 가지고 갔다고 하자. 갑자기 방에서 오이가 커지거나 작아지지 않는다. 그렇다고 몸도 틀지 않았으니 오이의 방향도 바뀌지 않았다. 그렇다 여기서 오이는 크기와 방향이 있는 백터고 난 이 오이를 평행이동 시켰다. 하지만 반대로 생각하면 오이는 가만히 있고 좌표계가 거실에서 방으로 바뀐 것일수도 있다. 하지만 오이의 크기와 방향은 바뀌지 않았다. 그렇다 오이는 rank1짜리 tensor였다 

여기서 한가지 공통점을 발견했는가? 바로 좌표계의 변화로 인해서 크기와 뱡향이 바뀌지 않았다는 것이다. 그렇다. tensor의 가장 중요한 특성은 바로 좌표계에 invariant(불변)하다는 것이다. (독립적)

여기서 우린 한가지 중요한 사실을 깨닫는다 아까 말햇던

> "rank 2의 텐서는 행렬이 될 수 있지만 모든 행렬이 텐서가 되는건 아니다"

이것의 비밀이 밝혀진다. 

한가지 재미있는 이야기를 들려주면 

지방과 서울간의 거리를 잴때 예를 들어 서울과 부산과의 거리가 450키로미터라고 하는데 이때 서울 어디서 출발해서 잰 거리일까 라는 의문이 들 수 있다 답은 광화문 사거리이다. 

자 광화문 사거리와 부산간에는 거리도 있지만 방향도 있다 그렇다 백터이다. 

근데 갑자기 규정이나 법이 바뀌에서 여의도 국회의사당에서 부터 재는 것으로 바뀌었다고 하자 이때에는 거리도 바뀌고 뱡향도 약간 바뀌게 된다. 

그렇다 원점에서 출발하는 위치백터는 원점이 바뀌면 크기와 방향이 모조리 바뀌는 백터이다. 즉, 이러한 백터는 tensor가 될 수 없다. 

그렇다 rank 1이 tensor는 백터가 될 수 있지만 모든 백터가 좌표계에 invariant한 것이 아니므로 모든 백터는 tensor가 아니다. 

심지어 이건 스칼라에서도 마찬기지인데 진동수와 파장은 스칼라이지만 멀어지거나 가까워짐에 따라 도플러효과로 인해 크기가 달라진다. 이때의 진동수와 파장은 스칼라이지만 rank 0의 tensor는 아니다. 

이것은 dyad와 그 이후에 차원에서도 동일하다 좌표계 그것이 핵심이다. 

하지만 이것도 엄격한 정의는 아니라고 한다. 

## 텐서곱 등판

사실 이부분은 딥러닝을 공부하는 단계에서는 중요한 것이 아니지만 양자컴퓨팅에서는 아주 중요하니 추후 양자컴퓨팅 포스팅에 추가하도록 하겠다. 

## 미안하다 사실 이거 보여주려고 어그로 끌었다 : 미분에서의 tensor

사실 tensorflow나 pytorch에서의 tensor의 의미는 백터의 변환에 대한 operator로써의 성격도 있지만, 사실 이것도 있다. 

> Tensor는 편미분과 자코비안 행렬로 변환된 gradient다

하.... 뭐 좀 쉽게 적을 수가 없다. 

1. 편미분 : 미분하고자 하는 변수 외에 나머지를 상수로 취급한다. 이정도만 일단 알자
2. 자코비안 행렬 ; 다변수 백터 행렬의 도함수 행렬이라는데 아래 수식을 보자 

    ![useful image]({{ site.url }}/assets/images/Untitled%205.png)

    이런 함수를 미분한다고 해보자
    
    ![useful image]({{ site.url }}/assets/images/Untitled%206.png)

    여기서 x와 y에 대한 각 미분에서 이걸 체인룰로 표현하면 이런식으로 나오게 되는데 

    자 그럼 각 미분변수 사이에는 무슨 관계가 있을까

    ![useful image]({{ site.url }}/assets/images/Untitled%207.png)

    dt만 없애면 된다. 자 이걸 행렬식으로 붙이면 

    ![useful image]({{ site.url }}/assets/images/Untitled%208.png)

    여기서 저 가운데 뚱뚱한 2x2짜리 행렬을 자코비안 행렬이라고 한다. 그렇다 du와 dv를 dx와 dy로 만들어줄 수 있는 행렬인것이다.  그래서 도함수 행렬이라고 하는거 같다. 

3. gradient : 스칼라장에서의 기울기, 결국엔 각 부분의 기울기라고 볼 수 있다. 

    ![useful image]({{ site.url }}/assets/images/Untitled%209.png)

    그 왜 우리 gradieTent descent하는 그거 

결국 tensor는 편미분에 해당되는 내용이며 미분에서의 기울기에 해당하는 부분이고 결국 공간이 얼마나 굽었냐에 해당되는 내용이다. 결국 그 기울기 또한 백터의 형태로 표현된다.  tensor는 미분연산에서의 기울기 자체라고 볼 수 있지만, 미분의 대상이 되는 백터와 행렬 또한 수학적 기준에 따라 tensor라고 볼 수 있는 것이다. 

> "결국 Tensor는 좌표계에 invariant한 백터와 행렬이며, tensor를 변환하는 함수이자 공간의 대한 기울기 인 것이다."

우리의 신경망은 tensor가 들어와서 tensor에 의해 변환되며, tensor에 의해 학습되는 말 그래도 tensor의 흐름(flow)에 따른 커다란 시스템 이었던 것이었다. tensorflow 닉값했네